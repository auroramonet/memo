<!doctype html><html lang=en-US dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Epoch 2: Micrograd, Part 2 | Memo Box</title><meta property="og:title" content="Epoch 2: Micrograd, Part 2"><meta property="og:type" content="article"><meta property="og:url" content="https://auroramonet.github.io/memo/posts/epoch2/"><meta property="og:image" content="https://files.catbox.moe/zh3y51.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://files.catbox.moe/zh3y51.png"><link rel=icon type=image/svg+xml href=/memo/favicon.svg><link rel=apple-touch-icon href=/memo/favicon.svg><meta name=theme-color content="#1a202c"><link rel=stylesheet href=/memo/css/main.min.7fa279f525716b6c44ad4d86208dcd4c1fb7ea3ce69b8f00834bf701768f3a60.css integrity="sha256-f6J59SVxa2xErU2GII3NTB+36jzmm48Ag0v3AXaPOmA=" crossorigin=anonymous><link rel=stylesheet href=/memo/css/custom.min.28b758b646b55f8499dd3a4acbd76a5e611500aa118f6843f784642628d4db6b.css integrity="sha256-KLdYtka1X4SZ3TpKy9dqXmEVAKoRj2hD94RkJijU22s=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script></head><body><header><nav class=path-nav><ul><li>/
<a href=/memo/>Memo Box</a>
/</li><li><a href=/memo/posts/>Posts</a>
/</li><li class=current><a href=/memo/posts/epoch2/>Epoch 2: Micrograd, Part 2</a></li></ul></nav></header><main><h1>Epoch 2: Micrograd, Part 2</h1><nav class=toc><strong>Table of contents</strong><div class=toc-content><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#content-completing-operations>Content: Completing Operations</a></li></ul></nav></div></nav><h2 id=intro>Intro</h2><p>Hi! I&rsquo;m Mon, this is Epoch 2, Micrograd, Part 2, in the previous epoch we learnt how to implement the <strong>addition</strong> and <strong>multiplication</strong> and build a tiny engine that can calculate <strong>local derivatives</strong> and <strong>global gradients</strong>.</p><p>Before jumping to Neural Network (nn), we should implement:</p><ol><li><strong>subtraction (errors, losses)</strong></li><li><strong>powers (squared loss)</strong></li><li><strong>division (normalization, scaling)</strong></li><li><strong>non-linear functions</strong></li></ol><h2 id=content-completing-operations>Content: Completing Operations</h2><p><strong>Subtraction</strong></p><p>$$
c = a - b
$$</p><p>rewrite:
$$
c = a + (-b)
$$</p><p>Derivatives:</p><p>$$
\frac{\partial c}{\partial a} = 1
$$</p><p>$$
\frac{\partial c}{\partial b} = -1
$$</p><p>means if b increases slightly, c decreases by the same amount</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Subtraction</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__sub__</span>(self, other):
</span></span><span style=display:flex><span>    other <span style=color:#f92672>=</span> other <span style=color:#66d9ef>if</span> isinstance(other, Value) <span style=color:#66d9ef>else</span> Value(other)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> self <span style=color:#f92672>+</span> (<span style=color:#f92672>-</span>other)
</span></span></code></pre></div><p><strong>Negation</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Negation</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__neg__</span>(self):
</span></span><span style=display:flex><span>    out <span style=color:#f92672>=</span> Value(<span style=color:#f92672>-</span>self<span style=color:#f92672>.</span>data, (self,), <span style=color:#e6db74>&#39;neg&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_backward</span>():
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>grad <span style=color:#f92672>+=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span> <span style=color:#f92672>*</span> out<span style=color:#f92672>.</span>grad
</span></span><span style=display:flex><span>    out<span style=color:#f92672>.</span>_backward <span style=color:#f92672>=</span> _backward
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> out
</span></span></code></pre></div><p><strong>Power</strong></p><p>Let:</p><p>$$
c = a^n
$$</p><p>Where:</p><ul><li><code>a</code> is a Value</li><li><code>n</code> is a constant</li></ul><p>Derivative:</p><p>$$
\frac{\partial c}{\partial a} = n \cdot a^{n-1}
$$</p><p>For here the exponent is not a <em>Value</em> to</p><ol><li>keep the engine minimal</li><li>avoid unnecessary graph complexity</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__pow__</span>(self, n):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>assert</span> isinstance(n, (int, float))
</span></span><span style=display:flex><span>    out <span style=color:#f92672>=</span> Value(self<span style=color:#f92672>.</span>data <span style=color:#f92672>**</span> n, (self,), <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;**</span><span style=color:#e6db74>{</span>n<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_backward</span>():
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>grad <span style=color:#f92672>+=</span> n <span style=color:#f92672>*</span> (self<span style=color:#f92672>.</span>data <span style=color:#f92672>**</span> (n <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>)) <span style=color:#f92672>*</span> out<span style=color:#f92672>.</span>grad
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    out<span style=color:#f92672>.</span>_backward <span style=color:#f92672>=</span> _backward
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> out
</span></span></code></pre></div><p><strong>Division (by power)</strong></p><p>Let:</p><p>$$
\frac{a}{b} = a \cdot b^{-1}
$$</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__truediv__</span>(self, other):
</span></span><span style=display:flex><span>    other <span style=color:#f92672>=</span> other <span style=color:#66d9ef>if</span> isinstance(other, Value) <span style=color:#66d9ef>else</span> Value(other)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> self <span style=color:#f92672>*</span> (other <span style=color:#f92672>**</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span></code></pre></div><div class=time><time datetime=2025-12-27>2025-12-27&nbsp;</time></div><div class=comments></div><div class=terminal-nav><div class=back-nav><a href=../ class=back-link>../</a></div></div></main><footer></footer></body></html>